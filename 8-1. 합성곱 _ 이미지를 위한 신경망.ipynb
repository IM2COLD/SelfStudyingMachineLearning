{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOssuADfwS5mt+Vqbd/bSuo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **주요 개념 정리**\n","\n","- 밀집층 = 완전 연결 층 : 뉴런마다 입력 개수만큼의 가중치가 있어, 불필요하게 자세한 함수가 만들어짐(over-fitting)\n","- 합성곱 : 입력 data에 도장을 찍듯이  이미지의 특징(윤곽)을 알아낸다. => 모든 feature를 사용하지 않고 일부 feature에만 가중치를 곱해주어 사용\n","\n","### 합성곱 신경망 CNN Convolution Neural Network\n","- 뉴런 = 필터 filter = 커널 kernel\n","- 커널 : 입력에 곱해지는 가중치\n","- 필터 : 도장판\n","=> 필터의 커널 크기가 (3,3)이다.\n","\n","- 합성곱 계산을 통해 얻은 출력 : Feature Map 특성 맵\n","- 여러 개의 필터를 사용 -> 만들어진 특성 맵은 순서대로 차곡차곡 쌓임\n","- 각각의 필터마다 가중치가 다르다\n","- 2차원 형태를 입력과 출력에서 모두 유지한다.\n","\n","- **1개 이상의 합성곱 층을 사용한 인공 신경망 : 합성곱 신경망 CNN이라 한다.**\n","- 클래스에 대한 확률을 계산하려면 마지막 층에 클래스 개수만큼의 뉴런을 가진 밀집층을 둔다.\n","\n","---\n","1. #### **입력값과 같은 size의 특성 맵을 만들기 위해 하는 패딩 : Same Padding**\n","- 패딩 padding : 입력 배열의 주위를 가상의 원소로 채우는 것\n","\n","- **Valid Padding 패딩 없이 순수한 입력 배열에서만 합성곱을 진행하여 특성 맵을 만드는 경우** => 특성 맵의 크기가 줄어들 수 밖에 없음\n","\n","#### 패딩을 하는 이유\n","- 패딩이 없다면 모서리의 입력값들은 다른 입력값들과 달리 커널 도장에 1번만 찍히게 된다. => 모서리에 있는 중요한 정보가 특성 맵으로 잘 전달되지 않을 가능성이 높다. -> 중앙부와 모서리 픽셀이 합성곱에 참여하는 비율이 크게 차이 난다.\n","\n","- 적절한 패딩은 이미지의 주변에 있는 정보를 잃어버리지 않도록 도와준다.\n","**layer를 만들 때 padding 매개변수 : same / valid**\n","-----\n","2. #### **필터의 이동의 크기 : Stride 스트라이드**\n","- layer를 만들 때 stride 매개변수 : n | 기본값 : 1\n","- 오른쪽으로 이동하는 크기 & 아래쪽으로 이동하는 크기 (a, b)의 튜플로 설정 가능\n","- 보통은 가로 세로 이동 크기를 같은 값으로 맞추어줌\n","----\n","3. #### **합성곱 층에서 만든 특성 맵의 가로세로 크기를 줄이는 역할 : 풀링층 Pooling**\n","- 마지막 차원의 개수(필터의 개수)는 그대로 유지한 채 너비와 높이만 줄어든 특성 맵으로 만든다.\n","- 입력값 위를 돌아다니며, 도장을 찍은 영영에서 가장 큰 값을 고르거나 평균값을 계산 -> **최대 풀링 & 평균 풀링**\n","- **풀링에는 가중치가 없다** -> training을 통해 train되어야 할 parameter가 없다.\n","- 합성곱 층 & 풀링 층에서 출력되는 값을 모두 특성 맵이라고 한다\n","- **합성곱 층에서는 필터가 한 칸씩 이동하기도 했지만, 풀링에서는 (n,n) 크기의 커널은 스트라이드 또한 n이다.**\n","\n","- ### 합성곱 신경망은 합성곱 층에서 특성 맵을 생성하고 풀링에서 크기를 줄이는 구조가 쌍을 이룬다.\n","- 풀링을 사용하는 이유 : 합성곱에서 풀링을 크게하여 맵을 줄이는 것보다 풀링 층에서 크기를 줄이는 것이 경험적으로 더 나은 성능을 내기 때문이다. -> 표현의 공간 크기를 점진적으로 줄여 네트워크의 매개변수 및 계산량을 줄이고 과적합을 제어할 수 있다.\n","- inference(추론, ex. 사과를 보고 사과라고 맞추는 것)를 하는데 있어 앞선 data가 모두 필요한 것이 아닌 적당량의 data만 있어도 됨\n"],"metadata":{"id":"SgBO0JuATZwQ"}},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OZcsnLQ_TQvp","executionInfo":{"status":"ok","timestamp":1701508243202,"user_tz":-540,"elapsed":290,"user":{"displayName":"이찬","userId":"00141605834555734115"}},"outputId":"e79885fb-ea5d-4fb2-cd79-0d38a7f8a998"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.convolutional.conv2d.Conv2D at 0x7ef318d32d40>"]},"metadata":{},"execution_count":7}],"source":["from tensorflow import keras\n","keras.layers.Conv2D(10, kernel_size = (3,3), activation = 'relu', padding = 'same')"]},{"cell_type":"code","source":["keras.layers.MaxPooling2D(2, strides = 2, padding = 'valid')\n","# 1번째 매개변수 : 풀링의 크기 -> 2 : 반으로 줄임\n","# n x n 커널 -> 스트라이드 : 자동으로 n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kw_qX9TQyWZs","executionInfo":{"status":"ok","timestamp":1701508245827,"user_tz":-540,"elapsed":288,"user":{"displayName":"이찬","userId":"00141605834555734115"}},"outputId":"f0734424-356a-4777-fbb4-b55c7337e251"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.layers.pooling.max_pooling2d.MaxPooling2D at 0x7ef28d6a8ac0>"]},"metadata":{},"execution_count":8}]}]}